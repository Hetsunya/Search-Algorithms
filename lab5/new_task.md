Давайте проанализируем результаты и разберёмся, почему TF-IDF работает медленнее, чем простой подсчёт встречаемости, на основе предоставленных данных.

---

### Анализ результатов

#### Общие данные:
- **Подготовка данных**: 0.0892 секунды — это время на токенизацию, построение TF-матрицы, подсчёт `doc_freq` и создание TF-IDF-матрицы. Это приемлемо для 10 документов и словаря из 10587 слов.
- **Размер словаря**: 10587 слов — достаточно большой словарь, что влияет на вычисления.
- **Количество документов**: 10 — небольшой корпус, но даже при этом разница в производительности заметна.

#### Запрос: "затрепетали на ветру знамена"
- **TF-IDF**:
  - Время: 0.007454 секунды.
  - Топ-5: `часть_8.txt` (0.0248), `часть_4.txt` (0.0130), `часть_1.txt` (0.0108), `часть_7.txt` (0.0102), `часть_3.txt` (0.0093).
  - Precision: 0.1000 (1 из 10 релевантен), Recall: 1.0000 (все релевантные найдены), F1: 0.1818.
- **Простой подсчёт**:
  - Время: 0.002836 секунды.
  - Топ-5: `часть_4.txt` (207), `часть_7.txt` (195), `часть_8.txt` (171), `часть_3.txt` (165), `часть_10.txt` (163).
  - Пересечение топ-5: 4 документа, уникальный для TF-IDF — `часть_1.txt`, для простого — `часть_10.txt`.

#### Запрос: "Гондора Мин-Риммон"
- **TF-IDF**:
  - Время: 0.008205 секунды.
  - Топ-5: `часть_3.txt` (0.0152), `часть_1.txt` (0.0085), `часть_8.txt` (0.0076), `часть_4.txt` (0.0076), `часть_5.txt` (0.0016).
  - Precision: 0.4000 (4 из 10 релевантны), Recall: 1.0000, F1: 0.5714.
- **Простой подсчёт**:
  - Время: 0.002530 секунды.
  - Топ-5: `часть_1.txt` (45), `часть_4.txt` (33), `часть_8.txt` (32), `часть_5.txt` (31), `часть_3.txt` (19).
  - Пересечение топ-5: 5 документов, нет уникальных.

---

### Почему TF-IDF медленнее?

TF-IDF выполняется медленнее простого подсчёта встречаемости по нескольким причинам:

1. **Сложность вычислений**:
   - **TF-IDF**: Для каждого запроса:
     - Формируется вектор запроса (`query_to_tfidf_vector`), что требует вычисления TF и умножения на IDF для каждого слова запроса — O(|query_tokens|).
     - Для каждого документа вычисляется косинусное сходство между вектором запроса и вектором документа. Это включает:
       - Скалярное произведение: O(|vocab|) в худшем случае, где `|vocab|` — размер словаря (10587 слов).
       - Вычисление норм векторов: ещё O(|vocab|).
       - Итоговая сложность для всех документов: O(|documents| * |vocab|) = O(10 * 10587) ≈ 105870 операций.
   - **Простой подсчёт**: 
     - Подсчитывает количество вхождений слов запроса в предобработанные токены документа с помощью `.count()`.
     - Сложность: O(|documents| * |doc_tokens| * |query_tokens|), где `|doc_tokens|` — средняя длина документа в токенах, а `|query_tokens|` — длина запроса (2-4 слова). Например, если средняя длина документа 1000 токенов, то O(10 * 1000 * 4) ≈ 40000 операций.
     - Это значительно меньше, чем у TF-IDF, так как не зависит от размера словаря.

2. **Размер словаря**:
   - У вас 10587 уникальных слов. TF-IDF работает с векторами размером до `|vocab|`, даже если в запросе и документе активны только несколько слов. Косинусное сходство требует итерирования по всем возможным ключам (объединение множеств ключей векторов), что увеличивает время.
   - Простой подсчёт игнорирует нерелевантные слова и работает только с токенами запроса, что делает его независимым от `|vocab|`.

3. **Предварительная подготовка**:
   - TF-IDF требует построения матрицы TF-IDF заранее (0.0892 секунды в вашем случае), что добавляет накладные расходы на старте. Хотя это делается один раз, последующие вычисления всё равно сложнее из-за векторных операций.
   - Простой подсчёт использует только предобработанные токены (`preprocessed_docs`) и выполняет линейный поиск, что проще и быстрее для небольшого числа документов.

4. **Реальная разница во времени**:
   - Для "затрепетали на ветру знамена": TF-IDF — 0.007454 с, простой — 0.002836 с (разница ≈ 2.6 раза).
   - Для "Гондора Мин-Риммон": TF-IDF — 0.008205 с, простой — 0.002530 с (разница ≈ 3.2 раза).
   - Разница объясняется тем, что TF-IDF тратит больше времени на векторные операции, особенно при большом словаре.

---

### Почему TF-IDF всё ещё полезен, несмотря на медлительность?

- **Качество**: 
  - Для "затрепетали на ветру знамена" TF-IDF поставил `часть_8.txt` (единственный релевантный) на первое место, а простой подсчёт — на третье. Это показывает, что TF-IDF лучше учитывает значимость слов.
  - Для "Гондора Мин-Риммон" оба метода нашли все 4 релевантных документа в топ-5, но TF-IDF дал более точное ранжирование (например, `часть_3.txt` на первом месте).

- **Метрики**:
  - Первый запрос: F1 = 0.1818 (низкая точность из-за малого числа релевантных документов).
  - Второй запрос: F1 = 0.5714 (лучше благодаря большему числу релевантных).

- **Смысловая точность**: TF-IDF снижает вес частых слов (например, "на" в "на ветру"), что делает его более устойчивым к шуму по сравнению с простым подсчётом.

---

### Как ещё ускорить TF-IDF?

1. **Уменьшить размер словаря**:
   - Удалите стоп-слова (например, "на", "в") перед построением `tf_matrix`. Это сократит `vocab` и ускорит вычисления.
   - Пример:
     ```python
     stop_words = {'на', 'в', 'и', 'с', 'по'}
     stemmed_tokens = [word for word in tokens if word not in stop_words]
     ```

2. **Ограничить векторы**:
   - В `cosine_similarity` итерируйтесь только по словам, присутствующим в запросе или документе, а не по всему `vocab`:
     ```python
     def cosine_similarity(vec1, vec2):
         dot_product = sum(v1 * vec2.get(key, 0) for key, v1 in vec1.items())
         norm1 = math.sqrt(sum(v1 ** 2 for v1 in vec1.values()))
         norm2 = math.sqrt(sum(v2 ** 2 for v2 in vec2.values()))
         return dot_product / (norm1 * norm2) if norm1 * norm2 > 0 else 0
     ```
   - Это снизит сложность до O(|query_tokens| + |doc_active_words|).

3. **Кэширование**:
   - Сохраняйте векторы TF-IDF для часто используемых запросов.

---

### Вывод

TF-IDF медленнее из-за:
- Высокой вычислительной сложности векторных операций.
- Зависимости от размера словаря (10587 слов).
- Дополнительных шагов (TF, IDF, косинусное сходство).

Простой подсчёт быстрее, так как работает линейно с токенами и не требует сложных математических операций. Однако TF-IDF оправдывает свою медлительность лучшим качеством ранжирования, что видно по точному выделению релевантных документов, особенно для специфичных запросов. Для ускорения можно оптимизировать словарь и вычисления, сохранив преимущества TF-IDF.